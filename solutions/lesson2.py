# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/01_lesson2.ipynb (unless otherwise specified).

__all__ = ['MNIST_URL', 'path', 'basic_model', 'Dataset', 'SequentialSampler', 'DataLoader', 'Learn', 'ModelMode',
           'DataBunch', 'Runner']

# Cell
from solutions.lesson1 import *
from fastai.datasets import *
import torch
from torch import nn
import numpy as np
from functools import wraps
from typing import List
from functools import partial

# Cell
MNIST_URL='http://deeplearning.net/data/mnist/mnist.pkl'
path = download_data(MNIST_URL, ext=".gz")
X_train, y_train, X_valid, y_valid = get_data(path)

# Cell
def basic_model(nh, torch_softmax=False):
    return nn.Sequential(
        nn.Linear(784, nh),
        nn.ReLU(),
        nn.Linear(nh, 10),
        nn.LogSoftmax() if torch_softmax else LogSoftmax()
    )

# Cell
class Dataset:
    def __init__(self, x, y):
        self.x = x
        self.y = y

    def __getitem__(self, index):
        return self.x[index], self.y[index]

    def __len__(self):
        return self.x.shape[0]

# Cell
class SequentialSampler:
    def __init__(self, ds):
        self.ds = ds

    def __iter__(self):
        for i in range(len(self.ds)):
            yield(i)

    def __len__(self):
        return len(self.ds)

# Cell
class DataLoader:
    def __init__(self, ds, bs, sampler=None):
        self.ds = ds
        self.bs = bs

        if callable(sampler):
            self.sampler = sampler(ds)
        else:
            self.sampler = sampler or SequentialSampler(ds)

    def __iter__(self):
        it = iter(self.sampler)
        nbatches = math.ceil(len(self) / self.bs)
        for _ in range(nbatches):
            try:
                idxs = []
                for _ in range(self.bs):
                    idxs.append(next(it))
                yield self.ds[idxs]
            except StopIteration:
                yield self.ds[idxs] # flush the final partial batch

    def __len__(self):
        return len(self.ds)

# Cell
class Learn:
    def __init__(self, model, optimizer, data, loss):
        self.model = model
        self.optimizer = optimizer
        self.data = data
        self.loss = loss

# Cell
class ModelMode:
    TRAIN = 0
    VALID = 1
    TEST = 2

# Cell
class DataBunch:
    def __init__(self, train_dl, valid_dl, test_dl=None, c=None):
        self.train_dl = train_dl
        self.valid_dl = valid_dl
        self.test_dl = test_dl
        self.c = c

# Cell
class Runner(object):
    def __init__(self, learn, cbs=None, cb_funcs=None):
        self.learn = learn
        cb_funcs = cb_funcs or []
        cbs = cbs or []
        self.cbs = cbs + [cb_func(self) for cb_func in cb_funcs]

        self.train_losses = []
        self.train_counts = []
        self.valid_losses = []
        self.valid_counts = []

        self.batches = 0

    def train(self):
        self.mode = ModelMode.TRAIN

    def valid(self):
        self.mode = ModelMode.VALID

    def mode(self):
        return self.mode

    def one_batch(self, xb, yb):
        self.xb, self.yb = xb, yb
        pred = self.learn.model(xb)
        loss = self.learn.loss(pred, yb)

        if self.mode == ModelMode.TRAIN:
            if self('on_batch_start'): return
            self.batches += 1
            self.train_losses.append(loss.item())
            self.train_counts.append(len(xb))
            loss.backward()
            if not self('on_step_start'): self.learn.optimizer.step()
            self.learn.optimizer.zero_grad()
            self('on_step_end')
            if self('on_batch_end'): return True

        if self.mode == ModelMode.VALID:
            self.valid_losses.append(loss.item())
            self.valid_counts.append(len(xb))

    def all_batches(self):
        if self('on_epoch_start'): return
        self.epochs += 1
        dl = self.learn.data.train_dl if self.mode == ModelMode.TRAIN else self.learn.data.valid_dl
        for xb, yb in dl:
            self.one_batch(xb, yb)
        self('on_epoch_end')

    def fit(self, epochs=1):
        self.total_batches = math.ceil(len(learn.data.train_dl) / learn.data.train_dl.bs) * epochs
        self('on_train_start')
        self.epochs = 0
        for _ in range(epochs):
            self.train()
            if self.all_batches(): return

            self.valid()
            if self.all_batches(): return
            print("Validation loss: {0:.4f}".format(self.loss(ModelMode.VALID)))
            self.epochs += 1
        self('on_train_end')

    def loss(self, mode: int):
        if mode == ModelMode.TRAIN:
            values, counts = self.train_losses, self.train_counts
        elif mode == ModelMode.VALID:
            values, counts = self.valid_losses, self.valid_counts
        else:
            raise ValueError("mode must be one of ModelMode.TRAIN or ModelMode.VALID.")

        total = sum(counts)
        weights = [i/total for i in counts]
        return sum([value*weight for value, weight in zip(values, weights)])

    def __call__(self, name):
        for cb in sorted(self.cbs, key=lambda x: x._order):
            f = getattr(cb, name, None)
            if f and f(): return True
        return False